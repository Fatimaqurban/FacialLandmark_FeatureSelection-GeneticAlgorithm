# -*- coding: utf-8 -*-
"""i211168_i211195_A2_Q.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mYi5XBzH8N6NZEuJSO7N6FafLrznuEsn
"""

from google.colab import drive
drive.mount('/content/data')

import os
import pandas as pd

# Defining my directory where CSV files are stored
directory = '/content/data/My Drive/A2_data'

# Initializing an empty list to store dataframes
dfs = []

# Loop through each CSV file in the directory
for filename in os.listdir(directory):
    if filename.endswith('.csv'):
        # Read the CSV file into a dataframe
        df = pd.read_csv(os.path.join(directory, filename))

        # Remove columns 1-3 and 298-433
        df = df.drop(df.columns[1:4], axis=1)
        df = df.drop(df.columns[298:433], axis=1)

        # Extract filename identifiers
        identifiers = filename.split('.')[0].split('-')
        modality = identifiers[0]
        emotion = identifiers[2]
        intensity = identifiers[3]
        statement = identifiers[4]
        repetition = identifiers[5]

        # Check if the file meets the criteria
        if modality == '01' and (emotion == '03' or emotion == '04') and intensity == '02' and statement == '02' and repetition == '02':
            # Append a column for emotion
            if emotion == '03':
                df['emotion'] = 0
            elif emotion == '04':
                df['emotion'] = 1

            # Append the dataframe to the list
            dfs.append(df)

# Merge all dataframes into a single dataframe
merged_df = pd.concat(dfs, ignore_index=True)

# prints no of rows and columns
merged_df.shape

#print first 100 rows
print(merged_df.head(100))

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical

# Step 1: Data Preprocessing
# Load data
merge_df = merged_df

# Filter data for happy and sad classes
merge_df = merge_df[merge_df.iloc[:, -1].isin([0, 1])]  # Assuming last column contains class labels 0, 1

# Separate features (X) and labels (y)
X = merge_df.iloc[:, :-1].values
y = merge_df.iloc[:, -1].values

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define number of outputs
n_outputs = 2

# Step 2: GA Initialization

# Define chromosome representation
chromosome_length = X_train.shape[1]  # Number of features
population_size = 2
mutation_rate = 0.1

# Step 3: Fitness Function
def evaluate_fitness(chromosome):
    selected_features = X_train[:, chromosome == 1]

    model = Sequential()
    model.add(Dense(120, input_dim=selected_features.shape[1], activation='relu'))
    model.add(Dense(80, activation='relu'))
    model.add(Dense(100, activation='relu'))
    model.add(Dense(n_outputs, activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    model.fit(selected_features, to_categorical(y_train), epochs=10, batch_size=32, verbose=0)

    _, accuracy = model.evaluate(selected_features, to_categorical(y_train), verbose=0)
    return accuracy

# Step 4: Selection, Crossover, and Mutation
def selection(population, fitness_scores):
    # Normalize fitness scores to probabilities
    probabilities = fitness_scores / np.sum(fitness_scores)

    # Select individuals based on their fitness scores
    selected_indices = np.random.choice(len(population), size=population_size, replace=False, p=probabilities)
    selected_population = population[selected_indices]

    return selected_population

def crossover(parent1, parent2):
    crossover_point = np.random.randint(1, len(parent1))
    child1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))
    child2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))
    return child1, child2

def mutate(chromosome):
    for i in range(len(chromosome)):
        if np.random.rand() < mutation_rate:
            chromosome[i] = 1 - chromosome[i]  # Flip bit
    return chromosome

# Step 5: GA Iteration
population = np.random.randint(2, size=(population_size, chromosome_length))
best_fitness = 0
best_chromosome = None
for iteration in range(5):  # Terminate after iterations
    fitness_scores = np.array([evaluate_fitness(chromosome) for chromosome in population])
    best_index = np.argmax(fitness_scores)
    if fitness_scores[best_index] > best_fitness:
        best_fitness = fitness_scores[best_index]
        best_chromosome = population[best_index]
    selected_population = selection(population, fitness_scores)
    new_population = []
    for i in range(population_size // 2):
        parent1, parent2 = selected_population[np.random.choice(len(selected_population), size=2, replace=False)]
        child1, child2 = crossover(parent1, parent2)
        child1 = mutate(child1)
        child2 = mutate(child2)
        new_population.extend([child1, child2])
    population = np.array(new_population)

# Step 6: Evaluation
selected_features = X_train[:, best_chromosome == 1]
X_test_selected = X_test[:, best_chromosome == 1]

model = Sequential()
model.add(Dense(120, input_dim=selected_features.shape[1], activation='relu'))
model.add(Dense(80, activation='relu'))
model.add(Dense(100, activation='relu'))
model.add(Dense(n_outputs, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(selected_features, to_categorical(y_train), epochs=10, batch_size=32, verbose=0)
test_loss, test_accuracy = model.evaluate(X_test_selected, to_categorical(y_test), verbose=0)

print("Accuracy: ", test_accuracy)